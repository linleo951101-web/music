"""
recognize.pyï¼ˆé«˜ç²¾æº–ç‰ˆï¼‰
- MFCC + Chroma ç‰¹å¾µ
- å¤šæ®µå–æ¨£ + å¹³å‡æŠ•ç¥¨
- ä¿¡å¿ƒå·®è·åˆ¤æ–·ï¼ˆé¿å…äº‚çŒœï¼‰
"""

import sys
import os
import json
import numpy as np
import librosa
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler

DB_FEATURES = "db_features.npy"
DB_META = "db_meta.json"

SR = 22050
N_MFCC = 20
N_CHROMA = 12

SEGMENT_DURATION = 6     # æ¯æ®µ 6 ç§’
SEGMENT_COUNT = 8        # å…±å– 8 æ®µï¼ˆç´„ 48 ç§’ï¼‰

CONFIDENCE_THRESHOLD = 0.75
MARGIN_THRESHOLD = 0.03


# =========================
# ç‰¹å¾µæ“·å–ï¼ˆMFCC + Chromaï¼‰
# =========================
def extract_feature(path, offset=0, duration=6):
    y, _ = librosa.load(path, sr=SR, mono=True,
                        offset=offset, duration=duration)

    if y.size == 0:
        return None

    mfcc = librosa.feature.mfcc(y=y, sr=SR, n_mfcc=N_MFCC)
    chroma = librosa.feature.chroma_stft(y=y, sr=SR)

    feat = np.concatenate([
        np.mean(mfcc, axis=1),
        np.mean(chroma, axis=1)
    ])

    return feat.astype("float32")


# =========================
# è¾¨è­˜ä¸»ç¨‹å¼
# =========================
def recognize(test_path, top_k=3):

    if not os.path.exists(test_path):
        print("âŒ æ‰¾ä¸åˆ°æ¸¬è©¦éŸ³æª”")
        return

    db = np.load(DB_FEATURES)
    with open(DB_META, "r", encoding="utf-8") as f:
        meta = json.load(f)

    # æ¨™æº–åŒ–ï¼ˆå¾ˆé‡è¦ï¼‰
    scaler = StandardScaler()
    db_norm = scaler.fit_transform(db)

    scores_all = []

    # å¤šæ®µå–æ¨£
    for i in range(SEGMENT_COUNT):
        offset = i * SEGMENT_DURATION
        feat = extract_feature(test_path, offset, SEGMENT_DURATION)
        if feat is None:
            continue

        feat_norm = scaler.transform(feat.reshape(1, -1))
        sims = cosine_similarity(feat_norm, db_norm).flatten()
        scores_all.append(sims)

    if not scores_all:
        print("âŒ ç„¡æ³•æ“·å–ç‰¹å¾µ")
        return

    # å¹³å‡æŠ•ç¥¨
    score_avg = np.mean(scores_all, axis=0)

    idx_sorted = np.argsort(-score_avg)

    best = idx_sorted[0]
    second = idx_sorted[1]

    best_score = score_avg[best]
    second_score = score_avg[second]
    margin = best_score - second_score

    print("\nğŸµ è¾¨è­˜çµæœï¼š\n")

    if best_score >= CONFIDENCE_THRESHOLD and margin >= MARGIN_THRESHOLD:
        print("âœ…ã€ç¢ºå®šçµæœã€‘")
        print(f"æ­Œæ›²ï¼š{meta[best]['filename']}")
        print(f"ä¿¡å¿ƒåº¦ï¼š{best_score:.4f}")
        print(f"èˆ‡ç¬¬äºŒåå·®è·ï¼š{margin:.4f}")
    else:
        print("âš ï¸ã€çµæœä¸å¤ ç¢ºå®šã€‘")
        print("å¯èƒ½å€™é¸æ­Œæ›²ï¼š")
        for rank in range(min(top_k, len(idx_sorted))):
            idx = idx_sorted[rank]
            print(f"{rank+1}. {meta[idx]['filename']} "
                  f"(ä¿¡å¿ƒåº¦: {score_avg[idx]:.4f})")


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•ï¼špython recognize.py test_clip.wav")
    else:
        recognize(sys.argv[1])
